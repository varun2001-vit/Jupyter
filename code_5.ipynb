{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "82f3271a2574c030bb07586ed2b0d9fa405de9f9c25dd1f3f81137bf2d3069b6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST',train=True,download=True,transform=transforms.Compose([transforms.ToTensor()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_correct(preds,labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        #convulution layer\n",
    "        self.conv1=nn.Conv2d(in_channels=1,out_channels=6,kernel_size=5)\n",
    "        self.conv2=nn.Conv2d(in_channels=6,out_channels=12,kernel_size=5)\n",
    "        #linear layer\n",
    "        self.fc1=nn.Linear(in_features=12*4*4,out_features=120)\n",
    "        self.fc2=nn.Linear(in_features=120,out_features=60)\n",
    "        self.out=nn.Linear(in_features=60,out_features=10)\n",
    "\n",
    "\n",
    "    def forward(self,t):\n",
    "        #input layer\n",
    "        t=t\n",
    "        #conv layer\n",
    "        t=self.conv1(t)\n",
    "        t=F.relu(t)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        t=self.conv2(t)\n",
    "        t=F.relu(t)\n",
    "        t=F.max_pool2d(t,kernel_size=2,stride=2)\n",
    "        #4th hidden layer\n",
    "        t=t.reshape(-1,12*4*4)\n",
    "        t=self.fc1(t)\n",
    "        t=F.relu(t)\n",
    "        #5th hidden layer\n",
    "        t=self.fc2(t)\n",
    "        t=F.relu(t)\n",
    "        #6th layer\n",
    "        t=self.out(t)\n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=next(iter(train_set))\n",
    "image,label=sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "params=OrderedDict(\n",
    "    lr=[0.01,0.001],batch_size=[1000,10000]\n",
    ")\n",
    "m=runmanager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    net=Network()\n",
    "    loader=DataLoader(train_set,batch_size=run.batch_size,shuffle=True)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=run.lr)\n",
    "    m.begin_run(run,net,loader)\n",
    "    for epoch in range(10):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images=batch[0]\n",
    "            labels=batch[1]\n",
    "            preds=net(images)\n",
    "            loss=F.cross_entropy(preds,labels)#claculate loss\n",
    "            optimizer.zero_grad() #removing previous grad\n",
    "            loss.backward() #calculationg grads\n",
    "            optimizer.step() #updationg weight\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('results')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix creation\n",
    "def get_all_preds(model,loader):\n",
    "    all_preds=torch.tensor([]) #empty ternsor\n",
    "    for batch in loader:\n",
    "        images,labels=batch\n",
    "        preds=model(images)\n",
    "        all_preds=torch.cat((all_preds,preds),dim=0)\n",
    "    return all_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    prediction_loader=torch.utils.data.DataLoader(train_set,batch_size=10000)\n",
    "    train_preds=get_all_preds(net,prediction_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_correct=get_num_correct(train_preds,train_set.targets)\n",
    "print(\"total correct:\",preds_correct)\n",
    "print(\"accuracy:\",preds_correct/len(train_set))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=torch.zeros(10,10,dtype=torch.int32)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in stacked:\n",
    "    tl,pl=p.tolist()\n",
    "    confusion_matrix[tl,pl]=confusion_matrix[tl,pl]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensorboard --logdir runs use this in conda cmd to open tenserboard\n",
    "tb=SummaryWriter()\n",
    "images,labels=next(iter(train_loader))\n",
    "grid=torchvision.utils.make_grid(images)\n",
    "tb.add_image('images',grid)\n",
    "tb.add_graph(net,images)\n",
    "tb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict,namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder():\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "        run=namedtuple('run',params.keys())\n",
    "        runs=[]\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(run(*v))\n",
    "        \n",
    "        return runs\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class runmanager():\n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.net = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "    def begin_run(self, run, network, loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.net = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.net, images)\n",
    "    \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count=0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time=time.time()\n",
    "        self.epoch_count+=1\n",
    "        self.epoch_loss=0\n",
    "        self.epoch_num_correct=0\n",
    "\n",
    "    def end_epoch(self):\n",
    "\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.net.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "\n",
    "\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "\n",
    "\n",
    "    @torch.no_grad\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "            \n",
    "    def save(self, fileName):\n",
    "\n",
    "            pd.DataFrame.from_dict(\n",
    "                self.run_data, orient='columns'\n",
    "            ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "            with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "    \n",
    "    def track_loss(self,loss):\n",
    "        self.epoch_loss+=loss.item()*self.loader.batch_size\n",
    "\n",
    "    def track_num_correct(self,preds,labels):\n",
    "        self.epoch_num_correct+=self._get_num_correct(preds,labels)\n",
    "   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cuda implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=torch.ones(1,1,28,28)\n",
    "net=Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=t.cuda()\n",
    "net=net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "gpu=net(t)\n",
    "gpu.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1=torch.tensor([1,2,3,4])\n",
    "t2=torch.tensor([1,2,23,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "source": [
    "t1=t1.to('cuda')\n",
    "t1.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "t2=t2.cuda()\n",
    "t2.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([ 2,  4, 26,  8], device='cuda:0')"
      ]
     },
     "metadata": {},
     "execution_count": 64
    }
   ],
   "source": [
    "t1+t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0  conv1.weight\ncuda:0  conv1.bias\ncuda:0  conv2.weight\ncuda:0  conv2.bias\ncuda:0  fc1.weight\ncuda:0  fc1.bias\ncuda:0  fc2.weight\ncuda:0  fc2.bias\ncuda:0  out.weight\ncuda:0  out.bias\n"
     ]
    }
   ],
   "source": [
    "for n,p in net.named_parameters():\n",
    "    print(p.device,'',n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 68
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using cuda\n",
    "class runmanager():\n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.net = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "    def begin_run(self, run, network, loader):\n",
    "\n",
    "        self.run_start_time = time.time()\n",
    "\n",
    "        self.run_params = run\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.net = network\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{run}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "\n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.net, images.to(getattr(run,'device','cpu'))\n",
    "        )\n",
    "    \n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count=0\n",
    "\n",
    "    def begin_epoch(self):\n",
    "        self.epoch_start_time=time.time()\n",
    "        self.epoch_count+=1\n",
    "        self.epoch_loss=0\n",
    "        self.epoch_num_correct=0\n",
    "\n",
    "    def end_epoch(self):\n",
    "\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.net.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "\n",
    "\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results['loss'] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results['epoch duration'] = epoch_duration\n",
    "        results['run duration'] = run_duration\n",
    "        for k,v in self.run_params._asdict().items(): results[k] = v\n",
    "        self.run_data.append(results)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "\n",
    "\n",
    "    @torch.no_grad\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "            \n",
    "    def save(self, fileName):\n",
    "\n",
    "            pd.DataFrame.from_dict(\n",
    "                self.run_data, orient='columns'\n",
    "            ).to_csv(f'{fileName}.csv')\n",
    "\n",
    "            with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "                json.dump(self.run_data, f, ensure_ascii=False, indent=4)\n",
    "            \n",
    "    \n",
    "    def track_loss(self,loss):\n",
    "        self.epoch_loss+=loss.item()*self.loader.batch_size\n",
    "\n",
    "    def track_num_correct(self,preds,labels):\n",
    "        self.epoch_num_correct+=self._get_num_correct(preds,labels)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training loop\n",
    "params=OrderedDict(\n",
    "    lr=[0.01,0.001],batch_size=[1000,10000],device=['cuda','cpu']\n",
    ")\n",
    "m=runmanager()\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    device=torch.device(run.device)\n",
    "    net=Network().to(device)\n",
    "    loader=DataLoader(train_set,batch_size=run.batch_size,shuffle=True)\n",
    "    optimizer=optim.Adam(net.parameters(),lr=run.lr)\n",
    "    m.begin_run(run,net,loader)\n",
    "    for epoch in range(10):\n",
    "        m.begin_epoch()\n",
    "        for batch in loader:\n",
    "            images=batch[0].to(device)\n",
    "            labels=batch[1].to(device)\n",
    "            preds=net(images)\n",
    "            loss=F.cross_entropy(preds,labels)#claculate loss\n",
    "            optimizer.zero_grad() #removing previous grad\n",
    "            loss.backward() #calculationg grads\n",
    "            optimizer.step() #updationg weight\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds,labels)\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "m.save('results')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}